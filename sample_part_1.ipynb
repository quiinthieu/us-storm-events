{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Case Study: Analyzing U.S. Storm Events for Disaster Preparedness \n",
    "\n",
    "In this case study, we will analyze storm event data to enhance disaster preparedness efforts in the U.S. We will follow a structured data analysis workflow comprising the following phases:\n",
    "\n",
    "1. **Ask**: Define the problem and confirm expectations.\n",
    "2. **Prepare**: Collect and store data for analysis.\n",
    "3. **Process**: Clean and transform data to ensure integrity.\n",
    "4. **Analyze**: Use data analysis tools to draw conclusions.\n",
    "5. **Share**: Interpret and communicate results to make data-driven decisions.\n",
    "6. **Act**: Put insights to work to address the original problem.\n",
    "\n",
    "We will utilize the open-source Storm Event Database provided by the National Oceanic and Atmospheric Administration (NOAA), available at [NOAA Storm Events Database](https://www.ncdc.noaa.gov/stormevents/ftp.jsp). This dataset contains comprehensive information about various storm events across the U.S., including details such as event type, location, and impact."
   ],
   "id": "be7169fdcf7f38c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "45d83b2e739d08a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ask\n",
    "\n",
    "### Problem Statement\n",
    "The U.S. experiences various storm events that can impact public safety, property, and infrastructure. Analyzing the patterns and impacts of these storms will provide insights that can inform disaster preparedness and response strategies.\n",
    "\n",
    "### Key Questions\n",
    "1. **What types of storm events are most prevalent in the U.S.?**  \n",
    "   Identify the most common storm events and their geographical distribution.\n",
    "\n",
    "2. **Where do storm events most frequently occur?**  \n",
    "   Map the geographical distribution of storm events to identify high-risk areas.\n",
    "\n",
    "3. **Are certain regions more prone to specific types of storm events?**  \n",
    "   Analyze the geographic hot spots for storm types to develop tailored regional preparedness plans.\n",
    "\n",
    "4. **What is the temporal distribution of storm events?**  \n",
    "   Analyze trends over time to understand seasonal patterns and changes in frequency.\n",
    "\n",
    "5. **What is the impact of different storm events on injuries, fatalities, and property damage?**  \n",
    "   Assess the severity of various storm types and their associated risks to prioritize high-risk events for preparedness planning.\n",
    "\n",
    "6. **How can this analysis inform disaster preparedness initiatives?**  \n",
    "   Determine actionable insights that can help stakeholders enhance response plans and allocate resources effectively."
   ],
   "id": "2ccab1df027afd0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "7e4d636d4bd247aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare\n",
    "\n",
    "### Data Sources\n",
    "For this analysis, we will use the Storm Event Database from National Centers for Environmental Information (NCEI) - National Oceanic and Atmospheric Administration (NOAA). The database currently contains data from January 1950 to June 2024. NCEI receives Storm Data from the National Weather Service (NWS). The NWS receives their information from a variety of sources, which include but are not limited to: county, state and federal emergency management officials, local law enforcement officials, skywarn spotters, NWS damage surveys, newspaper clipping services, the insurance industry and the general public, among others. An effort is made to use the best available information but because of time and resource constraints, information from these sources may be unverified by the NWS. Therefore, when using information from Storm Data, we should be cautious as the NWS does not guarantee the accuracy or validity of the information.\n",
    "The dataset can be accessed at [NOAA Storm Events Database](https://www.ncdc.noaa.gov/stormevents/ftp.jsp). We will limit the analysis horizon to 2014-2024 to focus on recent trends.\n",
    "\n",
    "### Data Collection\n",
    "The relevant files will be downloaded in CSV.GZ format, which is a compressed version of CSV files.\n",
    "\n",
    "### Data Description\n",
    "The dataset contains 51 columns with various types of information related to storm events. Below is the data dictionary presented in a table format:\n",
    "\n",
    "\n",
    "| Column Name        | Example                                                    | Description                                                                                                             |\n",
    "|:-------------------|:-----------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------|\n",
    "| begin_yearmonth    | 201212                                                     | The year and month that the event began (%Y%m format).                                                                  |\n",
    "| begin_day          | 1, 31                                                      | The day of the month that the event began (%-d format).                                                                 |\n",
    "| begin_time         | 800, 2359                                                  | The time of day that the event began (%-H%M format).                                                                    |\n",
    "| end_yearmonth      | 201301                                                     | The year and month that the event ended (%Y%m format).                                                                  |\n",
    "| end_day            | 01                                                         | The day of the month that the event ended (%-d format).                                                                 |\n",
    "| end_time           | 0001                                                       | The time of day that the event ended (%-H%M format).                                                                    |\n",
    "| episode_id         | 61280                                                      | ID assigned by NWS to denote the storm episode; may contain multiple events.                                            |\n",
    "| event_id           | 383097                                                     | ID assigned by NWS for each individual storm event (Primary database key field).                                        |\n",
    "| state              | GEORGIA                                                    | The state name where the event occurred (ALL CAPS).                                                                     |\n",
    "| state_fips         | 45                                                         | Unique number assigned to the county by NIST (State FIPS).                                                              |\n",
    "| year               | 2000                                                       | The four-digit year for the event in this record.                                                                       |\n",
    "| month_name         | January                                                    | The name of the month for the event (not abbreviated).                                                                  |\n",
    "| event_type         | Hail                                                       | The type of storm event (spelled out; not abbreviated).                                                                 |\n",
    "| cz_type            | C                                                          | Indicates whether the event happened in a County/Parish, NWS Public Forecast Zone, or Marine.                           |\n",
    "| cz_fips            | 245                                                        | The county FIPS number assigned by NIST or NWS Forecast Zone Number.                                                    |\n",
    "| cz_name            | AIKEN                                                      | Name assigned to the county FIPS number or NWS Forecast Zone.                                                           |\n",
    "| wfo                | CAE                                                        | The NWS Forecast Office’s area of responsibility in which the event occurred.                                           |\n",
    "| begin_date_time    | 11-DEC-21 03:50:00                                         | Start date and time of the event (%d-%b-%y %H:%M:%S).                                                                   |\n",
    "| cz_timezone        | EST-5                                                      | Time Zone for the County/Parish, Zone or Marine Name.                                                                   |\n",
    "| end_date_time      | 11-DEC-21 03:50:00                                         | End date and time of the event (%d-%b-%y %H:%M:%S).                                                                     |\n",
    "| injuries_direct    | 1                                                          | Number of injuries directly caused by the weather event.                                                                |\n",
    "| injuries_indirect  | 0                                                          | Number of injuries indirectly caused by the weather event.                                                              |\n",
    "| deaths_direct      | 0                                                          | Number of deaths directly caused by the weather event.                                                                  |\n",
    "| deaths_indirect    | 0                                                          | Number of deaths indirectly caused by the weather event.                                                                |\n",
    "| damage_property    | 10.00K                                                     | Estimated property damage incurred by the weather event.                                                                |\n",
    "| damage_crops       | 0.00K                                                      | Estimated damage to crops incurred by the weather event.                                                                |\n",
    "| source             | Public                                                     | Source reporting the weather event.                                                                                     |\n",
    "| magnitude          | 0.75                                                       | Measured extent of the magnitude type (only for wind speeds and hail size).                                             |\n",
    "| magnitude_type     | EG                                                         | Type of magnitude measurement (e.g., wind estimated gust).                                                              |\n",
    "| flood_cause        | Ice Jam                                                    | Reported cause of the flood.                                                                                            |\n",
    "| category           |                                                            | Unknown (During the time of downloading this particular file, NCDC has never seen anything provided within this field.) |\n",
    "| tor_f_scale        | EF0                                                        | Enhanced Fujita Scale describing tornado strength.                                                                      |\n",
    "| tor_length         | 0.66                                                       | Length of the tornado while on the ground (in miles).                                                                   |\n",
    "| tor_width          | 25                                                         | Width of the tornado while on the ground (in whole yards).                                                              |\n",
    "| tor_other_wfo      | DDC                                                        | Continuation of a tornado segment as it crossed from one NWS Forecast Office to another.                                |\n",
    "| tor_other_cz_state | KS                                                         | Two-character representation for the state name of the continuing tornado segment.                                      |\n",
    "| tor_other_cz_fips  | 41                                                         | FIPS number of the county for the continuing tornado segment.                                                           |\n",
    "| tor_other_cz_name  | DICKINSON                                                  | Name of the county for the continuing tornado segment.                                                                  |\n",
    "| begin_range        | 0.59                                                       | Distance to the nearest tenth of a mile to the location referenced.                                                     |\n",
    "| begin_azimuth      | ENE                                                        | 16-point compass direction from the location referenced.                                                                |\n",
    "| begin_location     | PINELAND                                                   | Name of city, town, or village from which the range is calculated.                                                      |\n",
    "| end_range          | 0.66                                                       | See begin_range.                                                                                                        |\n",
    "| end_azimuth        | WNW                                                        | See begin_azimuth.                                                                                                      |\n",
    "| end_location       | RUSK                                                       | See begin_location.                                                                                                     |\n",
    "| begin_lat          | 29.7898                                                    | Latitude in decimal degrees of the begin point of the event.                                                            |\n",
    "| begin_lon          | -98.6406                                                   | Longitude in decimal degrees of the begin point of the event.                                                           |\n",
    "| end_lat            | 29.7158                                                    | Latitude in decimal degrees of the end point of the event.                                                              |\n",
    "| end_lon            | -98.7744                                                   | Longitude in decimal degrees of the end point of the event.                                                             |\n",
    "| episode_narrative  | A strong upper level system over the southern Rockies...   | Narrative depicting the general nature of the episode.                                                                  |\n",
    "| event_narrative    | Heavy rain caused flash flooding across parts of Wilber... | Narrative providing descriptive details of the individual event.                                                        |\n",
    "\n",
    "### Data Storage\n",
    "The data will be stored in a local environment for analysis."
   ],
   "id": "7d62c9500d2cc5bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:00.177230Z",
     "start_time": "2024-09-25T03:59:00.174530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# To begin, let's import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import contextily as ctx\n",
    "import glob\n",
    "# import missingno as msno\n",
    "# \n",
    "# from shapely.geometry import Point\n",
    "# import geopandas as gpd\n",
    "# import folium\n",
    "\n",
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "id": "154448bb887011bb",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:04.761787Z",
     "start_time": "2024-09-25T03:59:00.188225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# In the data folder, we have lots of files. But for this analysis, we only need Storm Details files which have the prefix \"StormEvents_details-ftp_v1.0_d\".\n",
    "# So, let's define the file path pattern\n",
    "file_pattern = \"./data/StormEvents_details-ftp_v1.0_d*.csv.gz\"\n",
    "\n",
    "# Get a list of all files matching the pattern\n",
    "all_files = glob.glob(file_pattern)\n",
    "\n",
    "# Read and concatenate all files into a single DataFrame\n",
    "df_list = [pd.read_csv(file, compression='gzip') for file in all_files]\n",
    "df_details = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Rename column names to snake case for consistency \n",
    "df_details = df_details.clean_names()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_details.head()"
   ],
   "id": "a8e23b6fa0536bca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   begin_yearmonth  begin_day  begin_time  end_yearmonth  end_day  end_time  \\\n",
       "0           202112         11         349         202112       11       350   \n",
       "1           202112         11         249         202112       11       254   \n",
       "2           202112         11         325         202112       11       327   \n",
       "3           202112         11         232         202112       11       239   \n",
       "4           202112          6         724         202112        6       724   \n",
       "\n",
       "   episode_id  event_id      state  state_fips  year month_name  \\\n",
       "0      165322    999750  TENNESSEE          47  2021   December   \n",
       "1      165322    999613  TENNESSEE          47  2021   December   \n",
       "2      165322    999636  TENNESSEE          47  2021   December   \n",
       "3      165322    999604  TENNESSEE          47  2021   December   \n",
       "4      165321    999306  TENNESSEE          47  2021   December   \n",
       "\n",
       "          event_type cz_type  cz_fips   cz_name  wfo     begin_date_time  \\\n",
       "0            Tornado       C      165    SUMNER  OHX  11-DEC-21 03:49:00   \n",
       "1            Tornado       C       43   DICKSON  OHX  11-DEC-21 02:49:00   \n",
       "2  Thunderstorm Wind       C       37  DAVIDSON  OHX  11-DEC-21 03:25:00   \n",
       "3            Tornado       C       81   HICKMAN  OHX  11-DEC-21 02:32:00   \n",
       "4  Thunderstorm Wind       C       49  FENTRESS  OHX  06-DEC-21 07:24:00   \n",
       "\n",
       "  cz_timezone       end_date_time  injuries_direct  injuries_indirect  \\\n",
       "0       CST-6  11-DEC-21 03:50:00                0                  0   \n",
       "1       CST-6  11-DEC-21 02:54:00                0                  0   \n",
       "2       CST-6  11-DEC-21 03:27:00                0                  0   \n",
       "3       CST-6  11-DEC-21 02:39:00                0                  0   \n",
       "4       CST-6  06-DEC-21 07:24:00                0                  0   \n",
       "\n",
       "   deaths_direct  deaths_indirect damage_property damage_crops  \\\n",
       "0              0                0          10.00K        0.00K   \n",
       "1              0                0          10.00K        0.00K   \n",
       "2              0                0         250.00K        0.00K   \n",
       "3              0                0          50.00K        0.00K   \n",
       "4              0                0           3.00K        0.00K   \n",
       "\n",
       "             source  magnitude magnitude_type flood_cause  category  \\\n",
       "0  NWS Storm Survey        NaN            NaN         NaN       NaN   \n",
       "1  NWS Storm Survey        NaN            NaN         NaN       NaN   \n",
       "2  NWS Storm Survey       74.0             EG         NaN       NaN   \n",
       "3  NWS Storm Survey        NaN            NaN         NaN       NaN   \n",
       "4      Social Media       52.0             EG         NaN       NaN   \n",
       "\n",
       "  tor_f_scale  tor_length  tor_width tor_other_wfo tor_other_cz_state  \\\n",
       "0         EF0        1.72       50.0           OHX                 TN   \n",
       "1         EF0        5.41      175.0           NaN                NaN   \n",
       "2         NaN         NaN        NaN           NaN                NaN   \n",
       "3         EF1        8.54      400.0           NaN                NaN   \n",
       "4         NaN         NaN        NaN           NaN                NaN   \n",
       "\n",
       "   tor_other_cz_fips tor_other_cz_name  begin_range begin_azimuth  \\\n",
       "0              189.0            WILSON          3.0           WNW   \n",
       "1                NaN               NaN          1.0           ENE   \n",
       "2                NaN               NaN          1.0            NW   \n",
       "3                NaN               NaN          4.0            NW   \n",
       "4                NaN               NaN          1.0             W   \n",
       "\n",
       "  begin_location  end_range end_azimuth end_location  begin_lat  begin_lon  \\\n",
       "0     HUNTERS PT        3.0          NW   HUNTERS PT    36.3178   -86.3235   \n",
       "1        TIDWELL        2.0         ESE  BAKERSWORKS    36.0255   -87.3054   \n",
       "2      MAPLEWOOD        2.0          SW        AMQUI    36.2372   -86.7286   \n",
       "3           SPOT        4.0         NNW     PINEWOOD    35.9205   -87.6423   \n",
       "4      JAMESTOWN        1.0           W    JAMESTOWN    36.4322   -84.9405   \n",
       "\n",
       "   end_lat  end_lon                                  episode_narrative  \\\n",
       "0  36.3296 -86.2965  One of the worst tornado outbreaks ever record...   \n",
       "1  36.0736 -87.2330  One of the worst tornado outbreaks ever record...   \n",
       "2  36.2572 -86.7035  One of the worst tornado outbreaks ever record...   \n",
       "3  35.9725 -87.5068  One of the worst tornado outbreaks ever record...   \n",
       "4  36.4322 -84.9405  After some isolated thunderstorms moved across...   \n",
       "\n",
       "                                     event_narrative data_source  \n",
       "0  This small EF-0 tornado was determined through...         CSV  \n",
       "1  This tornado developed just southeast of the D...         CSV  \n",
       "2  Severe straight-line winds caused significant ...         CSV  \n",
       "3  This tornado touched down in far northwest Hic...         CSV  \n",
       "4  A Facebook report indicated trees and power li...         CSV  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin_yearmonth</th>\n",
       "      <th>begin_day</th>\n",
       "      <th>begin_time</th>\n",
       "      <th>end_yearmonth</th>\n",
       "      <th>end_day</th>\n",
       "      <th>end_time</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>state</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>year</th>\n",
       "      <th>month_name</th>\n",
       "      <th>event_type</th>\n",
       "      <th>cz_type</th>\n",
       "      <th>cz_fips</th>\n",
       "      <th>cz_name</th>\n",
       "      <th>wfo</th>\n",
       "      <th>begin_date_time</th>\n",
       "      <th>cz_timezone</th>\n",
       "      <th>end_date_time</th>\n",
       "      <th>injuries_direct</th>\n",
       "      <th>injuries_indirect</th>\n",
       "      <th>deaths_direct</th>\n",
       "      <th>deaths_indirect</th>\n",
       "      <th>damage_property</th>\n",
       "      <th>damage_crops</th>\n",
       "      <th>source</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>magnitude_type</th>\n",
       "      <th>flood_cause</th>\n",
       "      <th>category</th>\n",
       "      <th>tor_f_scale</th>\n",
       "      <th>tor_length</th>\n",
       "      <th>tor_width</th>\n",
       "      <th>tor_other_wfo</th>\n",
       "      <th>tor_other_cz_state</th>\n",
       "      <th>tor_other_cz_fips</th>\n",
       "      <th>tor_other_cz_name</th>\n",
       "      <th>begin_range</th>\n",
       "      <th>begin_azimuth</th>\n",
       "      <th>begin_location</th>\n",
       "      <th>end_range</th>\n",
       "      <th>end_azimuth</th>\n",
       "      <th>end_location</th>\n",
       "      <th>begin_lat</th>\n",
       "      <th>begin_lon</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>episode_narrative</th>\n",
       "      <th>event_narrative</th>\n",
       "      <th>data_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>349</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>350</td>\n",
       "      <td>165322</td>\n",
       "      <td>999750</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>C</td>\n",
       "      <td>165</td>\n",
       "      <td>SUMNER</td>\n",
       "      <td>OHX</td>\n",
       "      <td>11-DEC-21 03:49:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>11-DEC-21 03:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EF0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>50.0</td>\n",
       "      <td>OHX</td>\n",
       "      <td>TN</td>\n",
       "      <td>189.0</td>\n",
       "      <td>WILSON</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>HUNTERS PT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>HUNTERS PT</td>\n",
       "      <td>36.3178</td>\n",
       "      <td>-86.3235</td>\n",
       "      <td>36.3296</td>\n",
       "      <td>-86.2965</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>This small EF-0 tornado was determined through...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>249</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>254</td>\n",
       "      <td>165322</td>\n",
       "      <td>999613</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>C</td>\n",
       "      <td>43</td>\n",
       "      <td>DICKSON</td>\n",
       "      <td>OHX</td>\n",
       "      <td>11-DEC-21 02:49:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>11-DEC-21 02:54:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EF0</td>\n",
       "      <td>5.41</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>TIDWELL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>BAKERSWORKS</td>\n",
       "      <td>36.0255</td>\n",
       "      <td>-87.3054</td>\n",
       "      <td>36.0736</td>\n",
       "      <td>-87.2330</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>This tornado developed just southeast of the D...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>325</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>327</td>\n",
       "      <td>165322</td>\n",
       "      <td>999636</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>37</td>\n",
       "      <td>DAVIDSON</td>\n",
       "      <td>OHX</td>\n",
       "      <td>11-DEC-21 03:25:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>11-DEC-21 03:27:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>74.0</td>\n",
       "      <td>EG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>MAPLEWOOD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>AMQUI</td>\n",
       "      <td>36.2372</td>\n",
       "      <td>-86.7286</td>\n",
       "      <td>36.2572</td>\n",
       "      <td>-86.7035</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>Severe straight-line winds caused significant ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>232</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>239</td>\n",
       "      <td>165322</td>\n",
       "      <td>999604</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>C</td>\n",
       "      <td>81</td>\n",
       "      <td>HICKMAN</td>\n",
       "      <td>OHX</td>\n",
       "      <td>11-DEC-21 02:32:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>11-DEC-21 02:39:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EF1</td>\n",
       "      <td>8.54</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>SPOT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>PINEWOOD</td>\n",
       "      <td>35.9205</td>\n",
       "      <td>-87.6423</td>\n",
       "      <td>35.9725</td>\n",
       "      <td>-87.5068</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>This tornado touched down in far northwest Hic...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202112</td>\n",
       "      <td>6</td>\n",
       "      <td>724</td>\n",
       "      <td>202112</td>\n",
       "      <td>6</td>\n",
       "      <td>724</td>\n",
       "      <td>165321</td>\n",
       "      <td>999306</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>49</td>\n",
       "      <td>FENTRESS</td>\n",
       "      <td>OHX</td>\n",
       "      <td>06-DEC-21 07:24:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>06-DEC-21 07:24:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>52.0</td>\n",
       "      <td>EG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>JAMESTOWN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>JAMESTOWN</td>\n",
       "      <td>36.4322</td>\n",
       "      <td>-84.9405</td>\n",
       "      <td>36.4322</td>\n",
       "      <td>-84.9405</td>\n",
       "      <td>After some isolated thunderstorms moved across...</td>\n",
       "      <td>A Facebook report indicated trees and power li...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "ba22c65876c9777"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Process",
   "id": "cd0e4cdde66c313e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:05.142525Z",
     "start_time": "2024-09-25T03:59:04.833145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the DataFrame information\n",
    "df_details.info()"
   ],
   "id": "b05affd339697305",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 669746 entries, 0 to 669745\n",
      "Data columns (total 51 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   begin_yearmonth     669746 non-null  int64  \n",
      " 1   begin_day           669746 non-null  int64  \n",
      " 2   begin_time          669746 non-null  int64  \n",
      " 3   end_yearmonth       669746 non-null  int64  \n",
      " 4   end_day             669746 non-null  int64  \n",
      " 5   end_time            669746 non-null  int64  \n",
      " 6   episode_id          669746 non-null  int64  \n",
      " 7   event_id            669746 non-null  int64  \n",
      " 8   state               669746 non-null  object \n",
      " 9   state_fips          669746 non-null  int64  \n",
      " 10  year                669746 non-null  int64  \n",
      " 11  month_name          669746 non-null  object \n",
      " 12  event_type          669746 non-null  object \n",
      " 13  cz_type             669746 non-null  object \n",
      " 14  cz_fips             669746 non-null  int64  \n",
      " 15  cz_name             669746 non-null  object \n",
      " 16  wfo                 669746 non-null  object \n",
      " 17  begin_date_time     669746 non-null  object \n",
      " 18  cz_timezone         669746 non-null  object \n",
      " 19  end_date_time       669746 non-null  object \n",
      " 20  injuries_direct     669746 non-null  int64  \n",
      " 21  injuries_indirect   669746 non-null  int64  \n",
      " 22  deaths_direct       669746 non-null  int64  \n",
      " 23  deaths_indirect     669746 non-null  int64  \n",
      " 24  damage_property     533328 non-null  object \n",
      " 25  damage_crops        535619 non-null  object \n",
      " 26  source              669746 non-null  object \n",
      " 27  magnitude           348945 non-null  float64\n",
      " 28  magnitude_type      252901 non-null  object \n",
      " 29  flood_cause         72392 non-null   object \n",
      " 30  category            309 non-null     float64\n",
      " 31  tor_f_scale         15192 non-null   object \n",
      " 32  tor_length          15192 non-null   float64\n",
      " 33  tor_width           15192 non-null   float64\n",
      " 34  tor_other_wfo       1988 non-null    object \n",
      " 35  tor_other_cz_state  1988 non-null    object \n",
      " 36  tor_other_cz_fips   1988 non-null    float64\n",
      " 37  tor_other_cz_name   1988 non-null    object \n",
      " 38  begin_range         410429 non-null  float64\n",
      " 39  begin_azimuth       410429 non-null  object \n",
      " 40  begin_location      410429 non-null  object \n",
      " 41  end_range           410429 non-null  float64\n",
      " 42  end_azimuth         410429 non-null  object \n",
      " 43  end_location        410429 non-null  object \n",
      " 44  begin_lat           410429 non-null  float64\n",
      " 45  begin_lon           410429 non-null  float64\n",
      " 46  end_lat             410429 non-null  float64\n",
      " 47  end_lon             410429 non-null  float64\n",
      " 48  episode_narrative   669746 non-null  object \n",
      " 49  event_narrative     529683 non-null  object \n",
      " 50  data_source         669746 non-null  object \n",
      "dtypes: float64(11), int64(15), object(25)\n",
      "memory usage: 260.6+ MB\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:05.325130Z",
     "start_time": "2024-09-25T03:59:05.165756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Based on the data dictionary, we can drop the following columns: `category`\n",
    "df_details.drop(columns=['category'], inplace=True)"
   ],
   "id": "81fc75fe442b68da",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:07.857362Z",
     "start_time": "2024-09-25T03:59:05.380781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert `episode_id` and `event_id` to string type\n",
    "df_details['episode_id'] = df_details['episode_id'].astype(str)\n",
    "df_details['event_id'] = df_details['event_id'].astype(str)\n",
    "\n",
    "# Convert `begin_date_time` and `end_date_time` columns to datetime type. Current data follows the format 11-DEC-21 03:49:00\n",
    "df_details['begin_date_time'] = pd.to_datetime(df_details['begin_date_time'], format='%d-%b-%y %H:%M:%S')\n",
    "df_details['end_date_time'] = pd.to_datetime(df_details['end_date_time'], format='%d-%b-%y %H:%M:%S')\n",
    "\n",
    "# Convert `state_fips`, `month_name`, `event_type`, `cz_type`, `magnitude_type`, `tor_other_cz_state`, `tor_f_scale` to categorical type\n",
    "df_details['state_fips'] = df_details['state_fips'].astype('category')\n",
    "df_details['month_name'] = df_details['month_name'].astype('category')\n",
    "df_details['event_type'] = df_details['event_type'].astype('category')\n",
    "df_details['cz_type'] = df_details['cz_type'].astype('category')\n",
    "df_details['magnitude_type'] = df_details['magnitude_type'].astype('category')\n",
    "df_details['tor_other_cz_state'] = df_details['tor_other_cz_state'].astype('category')\n",
    "df_details['tor_f_scale'] = df_details['tor_f_scale'].astype('category')\n",
    "\n",
    "# Convert `tor_other_cz_fips` to integer type\n",
    "df_details['tor_other_cz_fips'] = df_details['tor_other_cz_fips'].astype('Int64')"
   ],
   "id": "19c6c9a6325401f2",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:08.128713Z",
     "start_time": "2024-09-25T03:59:07.887828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the data information\n",
    "df_details.info()"
   ],
   "id": "bf471852c85d51f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 669746 entries, 0 to 669745\n",
      "Data columns (total 50 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   begin_yearmonth     669746 non-null  int64         \n",
      " 1   begin_day           669746 non-null  int64         \n",
      " 2   begin_time          669746 non-null  int64         \n",
      " 3   end_yearmonth       669746 non-null  int64         \n",
      " 4   end_day             669746 non-null  int64         \n",
      " 5   end_time            669746 non-null  int64         \n",
      " 6   episode_id          669746 non-null  object        \n",
      " 7   event_id            669746 non-null  object        \n",
      " 8   state               669746 non-null  object        \n",
      " 9   state_fips          669746 non-null  category      \n",
      " 10  year                669746 non-null  int64         \n",
      " 11  month_name          669746 non-null  category      \n",
      " 12  event_type          669746 non-null  category      \n",
      " 13  cz_type             669746 non-null  category      \n",
      " 14  cz_fips             669746 non-null  int64         \n",
      " 15  cz_name             669746 non-null  object        \n",
      " 16  wfo                 669746 non-null  object        \n",
      " 17  begin_date_time     669746 non-null  datetime64[ns]\n",
      " 18  cz_timezone         669746 non-null  object        \n",
      " 19  end_date_time       669746 non-null  datetime64[ns]\n",
      " 20  injuries_direct     669746 non-null  int64         \n",
      " 21  injuries_indirect   669746 non-null  int64         \n",
      " 22  deaths_direct       669746 non-null  int64         \n",
      " 23  deaths_indirect     669746 non-null  int64         \n",
      " 24  damage_property     533328 non-null  object        \n",
      " 25  damage_crops        535619 non-null  object        \n",
      " 26  source              669746 non-null  object        \n",
      " 27  magnitude           348945 non-null  float64       \n",
      " 28  magnitude_type      252901 non-null  category      \n",
      " 29  flood_cause         72392 non-null   object        \n",
      " 30  tor_f_scale         15192 non-null   category      \n",
      " 31  tor_length          15192 non-null   float64       \n",
      " 32  tor_width           15192 non-null   float64       \n",
      " 33  tor_other_wfo       1988 non-null    object        \n",
      " 34  tor_other_cz_state  1988 non-null    category      \n",
      " 35  tor_other_cz_fips   1988 non-null    Int64         \n",
      " 36  tor_other_cz_name   1988 non-null    object        \n",
      " 37  begin_range         410429 non-null  float64       \n",
      " 38  begin_azimuth       410429 non-null  object        \n",
      " 39  begin_location      410429 non-null  object        \n",
      " 40  end_range           410429 non-null  float64       \n",
      " 41  end_azimuth         410429 non-null  object        \n",
      " 42  end_location        410429 non-null  object        \n",
      " 43  begin_lat           410429 non-null  float64       \n",
      " 44  begin_lon           410429 non-null  float64       \n",
      " 45  end_lat             410429 non-null  float64       \n",
      " 46  end_lon             410429 non-null  float64       \n",
      " 47  episode_narrative   669746 non-null  object        \n",
      " 48  event_narrative     529683 non-null  object        \n",
      " 49  data_source         669746 non-null  object        \n",
      "dtypes: Int64(1), category(7), datetime64[ns](2), float64(9), int64(12), object(19)\n",
      "memory usage: 224.8+ MB\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:09.422202Z",
     "start_time": "2024-09-25T03:59:08.162666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now let check for duplicates in the data\n",
    "duplicates = df_details.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")"
   ],
   "id": "b7cd97d663e2622b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "That's great news. We have no duplicated rows in our data. Let's proceed to check for missing values in the data.",
   "id": "cb3b6ebf75b11f86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:09.688272Z",
     "start_time": "2024-09-25T03:59:09.457746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing values in the data\n",
    "missing_values = df_details.isnull().sum()\n",
    "print(\"Missing values in the data:\")\n",
    "missing_values[missing_values > 0].sort_values(ascending=False)"
   ],
   "id": "7a7b43bb0017ef34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tor_other_cz_name     667758\n",
       "tor_other_wfo         667758\n",
       "tor_other_cz_state    667758\n",
       "tor_other_cz_fips     667758\n",
       "tor_f_scale           654554\n",
       "tor_length            654554\n",
       "tor_width             654554\n",
       "flood_cause           597354\n",
       "magnitude_type        416845\n",
       "magnitude             320801\n",
       "end_lat               259317\n",
       "end_lon               259317\n",
       "begin_range           259317\n",
       "begin_azimuth         259317\n",
       "begin_location        259317\n",
       "end_range             259317\n",
       "end_azimuth           259317\n",
       "end_location          259317\n",
       "begin_lat             259317\n",
       "begin_lon             259317\n",
       "event_narrative       140063\n",
       "damage_property       136418\n",
       "damage_crops          134127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We have several columns with missing values. Let's check for the columns with missing values.\n",
   "id": "e7287e0d5f06fbc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Start with `tor_f_scale`, `tor_length`, and `tor_width` columns.\n",
    "Based on the Data Dictionary provided at the beginning I assume columns like `tor_f_scale`, `tor_length`, and `tor_width` are relevant only for tornado events. It’s expected that these fields would be missing for non-tornado events. Let's prove it."
   ],
   "id": "822f3f28b6619814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:09.894965Z",
     "start_time": "2024-09-25T03:59:09.733846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select the tornado-specific columns\n",
    "tornado_columns = ['tor_f_scale', 'tor_length', 'tor_width']\n",
    "\n",
    "# Check if any of these columns is populated for `event_type` not containing 'Tornado'\n",
    "non_tornado = df_details[~df_details['event_type'].str.contains('Tornado', na=False)][tornado_columns].notnull().any(axis=1).sum()\n",
    "\n",
    "# Check if these columns are NOT all null for event_type containing 'Tornado'\n",
    "tornado= df_details[df_details['event_type'].str.contains('Tornado', na=False)][tornado_columns].isnull().all(axis=1).sum()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of non-tornado events with tornado-specific columns filled: {non_tornado}\")\n",
    "print(f\"Number of tornado events with missing tornado-specific columns: {tornado}\")"
   ],
   "id": "3bd667faddb1b296",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-tornado events with tornado-specific columns filled: 0\n",
      "Number of tornado events with missing tornado-specific columns: 0\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The result indicates that there are no missing values in the tornado-specific columns (`tor_f_scale`, `tor_length`, and `tor_width`) for events classified as tornadoes in the dataset. This confirms my assumption that these fields are only populated for tornado events and should not have missing values within that context.\n",
    "\n",
    "Thus, we don’t need to worry about these missing values in the broader dataset, as they are valid and expected for non-tornado events."
   ],
   "id": "20e4411c551b8756"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's move on to `tor_other_cz_name`, `tor_other_wfo`, `tor_other_cz_state`, and `tor_other_cz_fips` columns. Based on the Data Dictionary mentioned above, columns like `tor_other_cz_name`, `tor_other_wfo`, `tor_other_cz_state`, and `tor_other_cz_fips` apply only to tornadoes that cross into other geographical areas. If a tornado travels beyond its initial location, these additional columns should contain data.\n",
   "id": "cc9be814aefd3bec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:10.059903Z",
     "start_time": "2024-09-25T03:59:09.911494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the columns related to tornadoes that cross geographical areas\n",
    "tornado_other_location_cols = ['tor_other_cz_name', 'tor_other_wfo', 'tor_other_cz_state', 'tor_other_cz_fips']\n",
    "\n",
    "# 1. Prove there are only two outcomes: either all four are null or all four are not null\n",
    "# Create a mask where either all 4 are null or all 4 are not null\n",
    "all_null_or_not_null = (\n",
    "    (df_details[tornado_other_location_cols].isnull().all(axis=1)) | \n",
    "    (df_details[tornado_other_location_cols].notnull().all(axis=1))\n",
    ")\n",
    "\n",
    "# Check if any rows violate this condition\n",
    "invalid_rows = df_details[~all_null_or_not_null]\n",
    "\n",
    "if invalid_rows.empty:\n",
    "    print(\"There are no cases where only some of the 'tor_other_*' columns are null/non-null. The assumption holds.\")\n",
    "else:\n",
    "    print(\"There are cases where only some of the 'tor_other_*' columns are null/non-null:\")\n",
    "    print(invalid_rows)\n",
    "\n",
    "# 2. Prove that if the 4 columns are null, event_type is not Tornado, and if not null, event_type is Tornado and the original locations differs from the other locations\n",
    "\n",
    "# First check if event_type is not Tornado when all 4 columns are null\n",
    "non_tornado_mismatch = df_details[(df_details[tornado_other_location_cols].notnull().all(axis=1)) & (~df_details['event_type'].str.contains('Tornado', na=False))]\n",
    "\n",
    "# Check if the initial locations are different from the other locations when the 4 columns are not null and event_type is Tornado\n",
    "location_mismatch = df_details[(df_details[tornado_other_location_cols].notnull().all(axis=1)) & \n",
    "                               (df_details['event_type'].str.contains('Tornado', na=False)) &\n",
    "                               (df_details['cz_fips'] == df_details['tor_other_cz_fips']) &\n",
    "                                (df_details['cz_name'] == df_details['tor_other_cz_name']) &\n",
    "                                (df_details['wfo'] == df_details['tor_other_wfo'])]\n",
    "\n",
    "# Output the results\n",
    "if non_tornado_mismatch.empty and location_mismatch.empty:\n",
    "    print(\"All conditions hold: tornado events have 'tor_other_*' columns populated and locations differ when these columns are populated.\")\n",
    "else:\n",
    "    if not non_tornado_mismatch.empty:\n",
    "        print(\"There are non-tornado events where 'tor_other_*' columns are populated:\")\n",
    "        print(non_tornado_mismatch[['event_type'] + tornado_other_location_cols])\n",
    "    if not location_mismatch.empty:\n",
    "        print(\"There are tornado events where the initial location equals the other location but 'tor_other_*' columns are populated:\")\n",
    "        print(location_mismatch[['event_id', 'event_type', 'cz_name', 'wfo', 'cz_type', 'cz_fips',] + tornado_other_location_cols])"
   ],
   "id": "cdf7d03dc4ce187c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no cases where only some of the 'tor_other_*' columns are null/non-null. The assumption holds.\n",
      "All conditions hold: tornado events have 'tor_other_*' columns populated and locations differ when these columns are populated.\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This means that these columns only contain data when a tornado crosses into a new geographical area. If a tornado stays within one boundary, these columns remain null. This is consistent with the data dictionary and the expected behavior of the dataset.\n",
   "id": "9dd9e5604ddd96a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, let's check the `flood_cause` column. The `flood_cause` column is expected to be populated only for events classified as floods. Let's verify this assumption.",
   "id": "4e6816ead0284d03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:10.276271Z",
     "start_time": "2024-09-25T03:59:10.097746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if any of the flood events does not have the flood_cause column populated\n",
    "flood = df_details[df_details['event_type'].str.contains('Flood', na=False)]['flood_cause'].isnull().sum()\n",
    "\n",
    "# Check if any of the non-flood events have the flood_cause column populated\n",
    "non_flood = df_details[~df_details['event_type'].str.contains('Flood', na=False)]['flood_cause'].notnull().sum()\n",
    "\n",
    "# Display the result\n",
    "print(f\"Number of flood events with missing 'flood_cause': {flood}\")\n",
    "print(f\"Number of non-flood events with 'flood_cause' filled: {non_flood}\")"
   ],
   "id": "1913551a1c5016f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flood events with missing 'flood_cause': 2700\n",
      "Number of non-flood events with 'flood_cause' filled: 1409\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's check what `event_type` values are associated with these exceptions.",
   "id": "ecd53377237ed25c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:10.357350Z",
     "start_time": "2024-09-25T03:59:10.344297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the event types for non-flood events with flood_cause filled. Only display rows with count > 0\n",
    "non_flood_cause = df_details[~df_details['event_type'].str.contains('Flood', na=False) & df_details['flood_cause'].notnull()]['event_type'].value_counts()\n",
    "\n",
    "# Output the results\n",
    "non_flood_cause[non_flood_cause > 0]"
   ],
   "id": "6974b7b2a70804d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "Debris Flow    1409\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Debris flow can be influenced by several factors, but it typically occurs as a result of **heavy rainfall**. This could explain why the `flood_cause` column is populated for these events. So, no further action here.",
   "id": "bbcd9c75feae5095"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:10.385712Z",
     "start_time": "2024-09-25T03:59:10.372173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the event types for flood events with missing flood_cause\n",
    "flood_missing_cause = df_details[df_details['event_type'].str.contains('Flood', na=False) & df_details['flood_cause'].isnull()]['event_type'].value_counts()\n",
    "\n",
    "# Output the results\n",
    "flood_missing_cause[flood_missing_cause > 0]"
   ],
   "id": "c5e0017de070d1b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "Coastal Flood      2385\n",
       "Lakeshore Flood     315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since these flood events with missing `flood_cause` data represent a small portion of the dataset and our analysis does not focus heavily on `flood_cause`, we can retain these missing values as they are.",
   "id": "28a29b875e19d156"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's check the `magnitude` column. The `magnitude` column is expected to be populated for events classified as wind or hail. Let's verify this assumption.",
   "id": "99be8fb20c8ec5c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:10.494199Z",
     "start_time": "2024-09-25T03:59:10.412182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check non-null magnitude values and their associated event types\n",
    "non_null_magnitude_events = df_details[df_details['magnitude'].notnull()]['event_type'].value_counts()\n",
    "print(\"Event types with non-null magnitude:\")\n",
    "non_null_magnitude_events[non_null_magnitude_events > 0]"
   ],
   "id": "a65f048422745a77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event types with non-null magnitude:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "Thunderstorm Wind           178272\n",
       "Hail                         95763\n",
       "High Wind                    38392\n",
       "Marine Thunderstorm Wind     24362\n",
       "Strong Wind                  11197\n",
       "Marine High Wind               602\n",
       "Marine Hail                    281\n",
       "Marine Strong Wind              76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:10.674942Z",
     "start_time": "2024-09-25T03:59:10.558778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing values in the magnitude column\n",
    "missing_magnitude = df_details['magnitude'].isnull().sum()\n",
    "print(f\"Number of missing values in 'magnitude': {missing_magnitude}\\n\")\n",
    "\n",
    "# Identify event types with missing magnitude\n",
    "missing_magnitude_events = df_details[df_details['magnitude'].isnull()]['event_type'].value_counts()\n",
    "print(\"Event types with missing magnitude:\")\n",
    "missing_magnitude_events[missing_magnitude_events > 0]"
   ],
   "id": "37cace6bf75fed8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'magnitude': 320801\n",
      "\n",
      "Event types with missing magnitude:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "Flash Flood                   41325\n",
       "Winter Weather                40129\n",
       "Winter Storm                  31873\n",
       "Drought                       31702\n",
       "Flood                         29658\n",
       "Heavy Snow                    24229\n",
       "Tornado                       15192\n",
       "Heavy Rain                    14871\n",
       "Heat                          13209\n",
       "Excessive Heat                11608\n",
       "Extreme Cold/Wind Chill        9508\n",
       "Dense Fog                      7529\n",
       "Cold/Wind Chill                6295\n",
       "Frost/Freeze                   6087\n",
       "Blizzard                       5888\n",
       "High Surf                      4326\n",
       "Lightning                      3519\n",
       "Wildfire                       3447\n",
       "Funnel Cloud                   2959\n",
       "Tropical Storm                 2664\n",
       "Ice Storm                      2566\n",
       "Coastal Flood                  2385\n",
       "Waterspout                     2088\n",
       "Debris Flow                    1409\n",
       "Lake-Effect Snow               1028\n",
       "Dust Storm                      982\n",
       "Rip Current                     868\n",
       "Marine Tropical Storm           506\n",
       "Storm Surge/Tide                443\n",
       "Astronomical Low Tide           353\n",
       "Avalanche                       348\n",
       "Sleet                           321\n",
       "Lakeshore Flood                 315\n",
       "Hurricane                       274\n",
       "Tropical Depression             200\n",
       "Freezing Fog                    175\n",
       "Dense Smoke                     129\n",
       "Marine Hurricane/Typhoon         85\n",
       "Dust Devil                       78\n",
       "Volcanic Ashfall                 73\n",
       "Sneakerwave                      39\n",
       "Hurricane (Typhoon)              35\n",
       "Marine Tropical Depression       30\n",
       "Seiche                           26\n",
       "Marine Dense Fog                 15\n",
       "Tsunami                          10\n",
       "Marine Lightning                  2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The majority of the event types associated with missing `magnitude` values are not typically associated with specific magnitudes, such as \"Flash Flood\", \"Winter Weather\", \"Winter Storm\" and others while the event types that have non-null values for `magnitude` primarily include \"Thunderstorm Wind\", \"Hail\", and \"High Wind\". This aligns with the definition provided in the Data Dictionary. Thus, the missing values in the `magnitude` column are expected and do not require any further action.",
   "id": "a3af69f7c7b0da03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's check `magnitude_type` column. The `magnitude_type` column is expected to be populated for events classified as wind and has an associated value in the `magnitude` column. Let's verify this assumption.",
   "id": "f13cf1d440e0b12d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:10.889786Z",
     "start_time": "2024-09-25T03:59:10.746168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter rows where magnitude_type is not null\n",
    "magnitude_type_non_null = df_details[df_details['magnitude_type'].notnull()]\n",
    "\n",
    "# Check if magnitude_type rows have non-null values in magnitude (Condition 1)\n",
    "magnitude_missing = magnitude_type_non_null[magnitude_type_non_null['magnitude'].isnull()]\n",
    "\n",
    "# Define wind-related event types (Condition 2)\n",
    "wind_event_types = ['Thunderstorm Wind', 'High Wind', 'Strong Wind', 'Marine Thunderstorm Wind', \n",
    "                    'Marine High Wind', 'Marine Strong Wind']\n",
    "\n",
    "# Check if magnitude_type rows have wind-related event types (Condition 2)\n",
    "non_wind_events = magnitude_type_non_null[~magnitude_type_non_null['event_type'].isin(wind_event_types)]\n",
    "\n",
    "# Output results\n",
    "print(f\"Rows where magnitude_type is non-null but magnitude is null: {len(magnitude_missing)}\")\n",
    "print(f\"Event types with non-null magnitude_type but not wind-related: {len(non_wind_events)}\")\n",
    "\n",
    "# If any violations are found, display the problematic rows\n",
    "if not magnitude_missing.empty:\n",
    "    print(\"Rows with magnitude_type but missing magnitude:\")\n",
    "    print(magnitude_missing[['event_type', 'magnitude_type', 'magnitude']])\n",
    "\n",
    "if not non_wind_events.empty:\n",
    "    print(\"Rows with magnitude_type but non-wind event type:\")\n",
    "    print(non_wind_events[['event_type', 'magnitude_type']])"
   ],
   "id": "4ff1ee49d86f718f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where magnitude_type is non-null but magnitude is null: 0\n",
      "Event types with non-null magnitude_type but not wind-related: 0\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `magnitude_type` field is correctly populated only for wind-related events and always has an associated value in the `magnitude` column. No cases were found where `magnitude_type` was non-null without a corresponding value in `magnitude`, or where `magnitude_type` was filled for non-wind events. This confirms that the field is used appropriately in the dataset. So no further action is required.",
   "id": "76c51dbe8c1e9b52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we can move on to the other columns related to geographical locations (`end_lat`, `end_lon`, `begin_range`, `begin_azimuth`, `begin_location`, `end_range`, `end_azimuth`, `end_location`, `begin_lat`, `begin_lon`). I noticed that they all have the same number of rows with missing values. So, I suspect either all have values or are all null in a row, with no partial cases where some columns are populated while others are not. Let's verify this assumption.",
   "id": "d125639e8a85d12b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.064859Z",
     "start_time": "2024-09-25T03:59:10.932295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select the relevant columns\n",
    "geo_columns = ['end_lat', 'end_lon', 'begin_range', 'begin_azimuth', 'begin_location', \n",
    "               'end_range', 'end_azimuth', 'end_location', 'begin_lat', 'begin_lon']\n",
    "\n",
    "# Create a subset of just those columns\n",
    "geo_data = df_details[geo_columns]\n",
    "\n",
    "# Check if all columns are either fully null or fully populated\n",
    "all_null_or_all_filled = geo_data.isnull().all(axis=1) | geo_data.notnull().all(axis=1)\n",
    "\n",
    "# Count the number of rows where some columns are null but others are not\n",
    "partially_null_rows_count = (~all_null_or_all_filled).sum()\n",
    "\n",
    "print(f\"Number of rows where some columns are null and others are filled: {partially_null_rows_count}\")"
   ],
   "id": "5ba93f7d3046e12a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where some columns are null and others are filled: 0\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So, that confirms my theory. These columns are either all being populated or all null in a row, with no partial cases where some columns are populated while others are not. This leads to me to believe that these columns are not always required for every event in the dataset. It makes sense that events like droughts or heat waves, for example, may not have clearly defined start or end geographical locations because they can affect broad regions over time rather than specific points.\n",
    "\n",
    "We can check if the missing geographical data is associated with specific types of events that typically don’t have a clear starting or ending location. "
   ],
   "id": "ca3f8ac5e5ee557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.233791Z",
     "start_time": "2024-09-25T03:59:11.092263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter rows where the geographical data is missing\n",
    "missing_geo_data = df_details[geo_data.isnull().all(axis=1)]\n",
    "\n",
    "# Count the event types for these rows\n",
    "missing_geo_event_types = missing_geo_data['event_type'].value_counts()\n",
    "\n",
    "print(\"Event types associated with missing geographical data:\")\n",
    "missing_geo_event_types[missing_geo_event_types > 0]"
   ],
   "id": "4a2be9d54f772b1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event types associated with missing geographical data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "Winter Weather                40129\n",
       "High Wind                     38392\n",
       "Winter Storm                  31873\n",
       "Drought                       31702\n",
       "Heavy Snow                    24229\n",
       "Heat                          13209\n",
       "Excessive Heat                11608\n",
       "Strong Wind                   11197\n",
       "Extreme Cold/Wind Chill        9508\n",
       "Dense Fog                      7529\n",
       "Cold/Wind Chill                6295\n",
       "Frost/Freeze                   6087\n",
       "Blizzard                       5888\n",
       "High Surf                      4326\n",
       "Wildfire                       3447\n",
       "Tropical Storm                 2664\n",
       "Ice Storm                      2566\n",
       "Coastal Flood                  2385\n",
       "Lake-Effect Snow               1028\n",
       "Dust Storm                      982\n",
       "Rip Current                     868\n",
       "Marine Tropical Storm           506\n",
       "Storm Surge/Tide                443\n",
       "Astronomical Low Tide           353\n",
       "Avalanche                       348\n",
       "Sleet                           321\n",
       "Lakeshore Flood                 315\n",
       "Hurricane                       274\n",
       "Tropical Depression             200\n",
       "Freezing Fog                    175\n",
       "Dense Smoke                     129\n",
       "Marine Hurricane/Typhoon         85\n",
       "Volcanic Ashfall                 73\n",
       "Sneakerwave                      39\n",
       "Hurricane (Typhoon)              35\n",
       "Marine Tropical Depression       30\n",
       "Seiche                           26\n",
       "Marine Dense Fog                 15\n",
       "Tsunami                          10\n",
       "Tornado                           9\n",
       "Waterspout                        7\n",
       "Thunderstorm Wind                 6\n",
       "Hail                              4\n",
       "Marine Thunderstorm Wind          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This result supports the idea that the missing geographical data (latitude, longitude, range, azimuth, and location) is associated with events that typically don’t have well-defined start and end points.\n",
    "\n",
    "Given this context, we can conclude that the missing values in these columns are valid and do not require further action."
   ],
   "id": "e87c333d7dfd1a8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's check `event_narrative` column. The `event_narrative` column provides descriptive details of the individual event. Let's verify if the missing values in this column are associated with specific event types.",
   "id": "f0d69ddda7d99f46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.338695Z",
     "start_time": "2024-09-25T03:59:11.277995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing values in the event_narrative column\n",
    "missing_narrative_events = df_details[df_details['event_narrative'].isnull()]\n",
    "\n",
    "# Count the event types in these rows\n",
    "event_narrative_counts = missing_narrative_events['event_type'].value_counts()\n",
    "\n",
    "print(\"Event types with missing event_narrative:\")\n",
    "event_narrative_counts[event_narrative_counts > 0]"
   ],
   "id": "d78b60d8df60a8ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event types with missing event_narrative:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "Hail                        50120\n",
       "Winter Weather              10362\n",
       "Drought                     10090\n",
       "Thunderstorm Wind            8795\n",
       "Winter Storm                 7033\n",
       "High Wind                    6845\n",
       "Heat                         5986\n",
       "Excessive Heat               4923\n",
       "Heavy Snow                   4547\n",
       "Strong Wind                  4363\n",
       "High Surf                    3844\n",
       "Extreme Cold/Wind Chill      3549\n",
       "Dense Fog                    3347\n",
       "Cold/Wind Chill              3024\n",
       "Marine Thunderstorm Wind     2499\n",
       "Frost/Freeze                 2373\n",
       "Blizzard                     2097\n",
       "Heavy Rain                   1374\n",
       "Flood                         886\n",
       "Wildfire                      787\n",
       "Lake-Effect Snow              566\n",
       "Ice Storm                     487\n",
       "Funnel Cloud                  470\n",
       "Tropical Storm                363\n",
       "Flash Flood                   244\n",
       "Waterspout                    113\n",
       "Lakeshore Flood               109\n",
       "Coastal Flood                 105\n",
       "Marine Tropical Storm          94\n",
       "Astronomical Low Tide          81\n",
       "Volcanic Ashfall               65\n",
       "Marine Hail                    64\n",
       "Rip Current                    58\n",
       "Storm Surge/Tide               57\n",
       "Dust Storm                     52\n",
       "Dense Smoke                    47\n",
       "Freezing Fog                   45\n",
       "Marine High Wind               36\n",
       "Hurricane                      35\n",
       "Lightning                      34\n",
       "Avalanche                      31\n",
       "Marine Hurricane/Typhoon       24\n",
       "Sleet                          13\n",
       "Hurricane (Typhoon)             8\n",
       "Dust Devil                      5\n",
       "Marine Strong Wind              4\n",
       "Seiche                          3\n",
       "Tropical Depression             3\n",
       "Debris Flow                     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In our analysis, we observed a significant number of missing values in the `event_narrative` column. Given that the narrative primarily provides additional context rather than contributing to the quantitative analysis, we will not be filling in these missing values. Instead, we will retain the existing data as is, ensuring that our analysis remains focused on quantifiable metrics. Furthermore, since the `episode_narrative` column has no missing values, it may serve as a useful supplementary reference, although it will not be included in our main analysis.",
   "id": "14ef129fbf152594"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "According to the National Weather Service (NWS), property and crop damage amounts are broad estimates based on available data at the time of publication. These figures are derived from various sources and are not adjusted for inflation, meaning they reflect the values as entered at the time of the event. The values are not standardized and may vary based on the source of the information. Given these factors, we should treat these values as approximations rather than precise figures. We could reasonably leave the `damage_property` and `damage_crops` columns as they are and impute missing values with 0. ",
   "id": "24c87fb3f8ef503c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.389572Z",
     "start_time": "2024-09-25T03:59:11.367720Z"
    }
   },
   "cell_type": "code",
   "source": "df_details['damage_property'].value_counts()",
   "id": "a9fa17197f89a8cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_property\n",
       "0.00K      399893\n",
       "1.00K       21073\n",
       "5.00K       15700\n",
       "10.00K      13847\n",
       "2.00K       12713\n",
       "            ...  \n",
       "447.00K         1\n",
       "32.60M          1\n",
       "18.80M          1\n",
       "1.04M           1\n",
       "222.50M         1\n",
       "Name: count, Length: 1325, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.445810Z",
     "start_time": "2024-09-25T03:59:11.443548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function to convert values in 'damage_*' col to float. If the value is not a string, return 0.\n",
    "def convert_damage(value):\n",
    "    if isinstance(value, str):\n",
    "        if 'K' in value:\n",
    "            return float(value.replace('K', '')) * 1000\n",
    "        elif 'M' in value:\n",
    "            return float(value.replace('M', '')) * 1000000\n",
    "        elif 'B' in value:\n",
    "            return float(value.replace('B', '')) * 1000000000\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ],
   "id": "c1fd9179a9a41e99",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.602160Z",
     "start_time": "2024-09-25T03:59:11.475749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the conversion\n",
    "df_details['imputed_damage_property'] = df_details['damage_property'].apply(convert_damage)\n",
    "\n",
    "# Check for remaining missing values\n",
    "remaining_missing = df_details['imputed_damage_property'].isnull().sum()\n",
    "print(f\"Remaining missing values in 'imputed_damage_property': {remaining_missing}\")"
   ],
   "id": "cced0aa8dcff2126",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values in 'imputed_damage_property': 0\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Similar for `damage_crops` column, we will impute the missing values. We will follow the same approach as we did for the `damage_property` column.",
   "id": "9e5459ff0ca70c5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.778491Z",
     "start_time": "2024-09-25T03:59:11.651479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert 'damage_crops' to numeric\n",
    "df_details['imputed_damage_crops'] = df_details['damage_crops'].apply(convert_damage)\n",
    "\n",
    "# Check for remaining missing values\n",
    "remaining_missing_crops = df_details['imputed_damage_crops'].isnull().sum()\n",
    "print(f\"Remaining missing values in 'imputed_damage_crops': {remaining_missing_crops}\")"
   ],
   "id": "185eb34b0e5da7b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values in 'imputed_damage_crops': 0\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have investigated and handled the issues with the dataset. Let's take a look at the cleaned data. ",
   "id": "6a3ccc207b80f5da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:11.821451Z",
     "start_time": "2024-09-25T03:59:11.811713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the first few rows of the cleaned DataFrame\n",
    "df_details.head()"
   ],
   "id": "b2cbba34c7ec03cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   begin_yearmonth  begin_day  begin_time  end_yearmonth  end_day  end_time  \\\n",
       "0           202112         11         349         202112       11       350   \n",
       "1           202112         11         249         202112       11       254   \n",
       "2           202112         11         325         202112       11       327   \n",
       "3           202112         11         232         202112       11       239   \n",
       "4           202112          6         724         202112        6       724   \n",
       "\n",
       "  episode_id event_id      state state_fips  year month_name  \\\n",
       "0     165322   999750  TENNESSEE         47  2021   December   \n",
       "1     165322   999613  TENNESSEE         47  2021   December   \n",
       "2     165322   999636  TENNESSEE         47  2021   December   \n",
       "3     165322   999604  TENNESSEE         47  2021   December   \n",
       "4     165321   999306  TENNESSEE         47  2021   December   \n",
       "\n",
       "          event_type cz_type  cz_fips   cz_name  wfo     begin_date_time  \\\n",
       "0            Tornado       C      165    SUMNER  OHX 2021-12-11 03:49:00   \n",
       "1            Tornado       C       43   DICKSON  OHX 2021-12-11 02:49:00   \n",
       "2  Thunderstorm Wind       C       37  DAVIDSON  OHX 2021-12-11 03:25:00   \n",
       "3            Tornado       C       81   HICKMAN  OHX 2021-12-11 02:32:00   \n",
       "4  Thunderstorm Wind       C       49  FENTRESS  OHX 2021-12-06 07:24:00   \n",
       "\n",
       "  cz_timezone       end_date_time  injuries_direct  injuries_indirect  \\\n",
       "0       CST-6 2021-12-11 03:50:00                0                  0   \n",
       "1       CST-6 2021-12-11 02:54:00                0                  0   \n",
       "2       CST-6 2021-12-11 03:27:00                0                  0   \n",
       "3       CST-6 2021-12-11 02:39:00                0                  0   \n",
       "4       CST-6 2021-12-06 07:24:00                0                  0   \n",
       "\n",
       "   deaths_direct  deaths_indirect damage_property damage_crops  \\\n",
       "0              0                0          10.00K        0.00K   \n",
       "1              0                0          10.00K        0.00K   \n",
       "2              0                0         250.00K        0.00K   \n",
       "3              0                0          50.00K        0.00K   \n",
       "4              0                0           3.00K        0.00K   \n",
       "\n",
       "             source  magnitude magnitude_type flood_cause tor_f_scale  \\\n",
       "0  NWS Storm Survey        NaN            NaN         NaN         EF0   \n",
       "1  NWS Storm Survey        NaN            NaN         NaN         EF0   \n",
       "2  NWS Storm Survey       74.0             EG         NaN         NaN   \n",
       "3  NWS Storm Survey        NaN            NaN         NaN         EF1   \n",
       "4      Social Media       52.0             EG         NaN         NaN   \n",
       "\n",
       "   tor_length  tor_width tor_other_wfo tor_other_cz_state  tor_other_cz_fips  \\\n",
       "0        1.72       50.0           OHX                 TN                189   \n",
       "1        5.41      175.0           NaN                NaN               <NA>   \n",
       "2         NaN        NaN           NaN                NaN               <NA>   \n",
       "3        8.54      400.0           NaN                NaN               <NA>   \n",
       "4         NaN        NaN           NaN                NaN               <NA>   \n",
       "\n",
       "  tor_other_cz_name  begin_range begin_azimuth begin_location  end_range  \\\n",
       "0            WILSON          3.0           WNW     HUNTERS PT        3.0   \n",
       "1               NaN          1.0           ENE        TIDWELL        2.0   \n",
       "2               NaN          1.0            NW      MAPLEWOOD        2.0   \n",
       "3               NaN          4.0            NW           SPOT        4.0   \n",
       "4               NaN          1.0             W      JAMESTOWN        1.0   \n",
       "\n",
       "  end_azimuth end_location  begin_lat  begin_lon  end_lat  end_lon  \\\n",
       "0          NW   HUNTERS PT    36.3178   -86.3235  36.3296 -86.2965   \n",
       "1         ESE  BAKERSWORKS    36.0255   -87.3054  36.0736 -87.2330   \n",
       "2          SW        AMQUI    36.2372   -86.7286  36.2572 -86.7035   \n",
       "3         NNW     PINEWOOD    35.9205   -87.6423  35.9725 -87.5068   \n",
       "4           W    JAMESTOWN    36.4322   -84.9405  36.4322 -84.9405   \n",
       "\n",
       "                                   episode_narrative  \\\n",
       "0  One of the worst tornado outbreaks ever record...   \n",
       "1  One of the worst tornado outbreaks ever record...   \n",
       "2  One of the worst tornado outbreaks ever record...   \n",
       "3  One of the worst tornado outbreaks ever record...   \n",
       "4  After some isolated thunderstorms moved across...   \n",
       "\n",
       "                                     event_narrative data_source  \\\n",
       "0  This small EF-0 tornado was determined through...         CSV   \n",
       "1  This tornado developed just southeast of the D...         CSV   \n",
       "2  Severe straight-line winds caused significant ...         CSV   \n",
       "3  This tornado touched down in far northwest Hic...         CSV   \n",
       "4  A Facebook report indicated trees and power li...         CSV   \n",
       "\n",
       "   imputed_damage_property  imputed_damage_crops  \n",
       "0                  10000.0                   0.0  \n",
       "1                  10000.0                   0.0  \n",
       "2                 250000.0                   0.0  \n",
       "3                  50000.0                   0.0  \n",
       "4                   3000.0                   0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin_yearmonth</th>\n",
       "      <th>begin_day</th>\n",
       "      <th>begin_time</th>\n",
       "      <th>end_yearmonth</th>\n",
       "      <th>end_day</th>\n",
       "      <th>end_time</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>state</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>year</th>\n",
       "      <th>month_name</th>\n",
       "      <th>event_type</th>\n",
       "      <th>cz_type</th>\n",
       "      <th>cz_fips</th>\n",
       "      <th>cz_name</th>\n",
       "      <th>wfo</th>\n",
       "      <th>begin_date_time</th>\n",
       "      <th>cz_timezone</th>\n",
       "      <th>end_date_time</th>\n",
       "      <th>injuries_direct</th>\n",
       "      <th>injuries_indirect</th>\n",
       "      <th>deaths_direct</th>\n",
       "      <th>deaths_indirect</th>\n",
       "      <th>damage_property</th>\n",
       "      <th>damage_crops</th>\n",
       "      <th>source</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>magnitude_type</th>\n",
       "      <th>flood_cause</th>\n",
       "      <th>tor_f_scale</th>\n",
       "      <th>tor_length</th>\n",
       "      <th>tor_width</th>\n",
       "      <th>tor_other_wfo</th>\n",
       "      <th>tor_other_cz_state</th>\n",
       "      <th>tor_other_cz_fips</th>\n",
       "      <th>tor_other_cz_name</th>\n",
       "      <th>begin_range</th>\n",
       "      <th>begin_azimuth</th>\n",
       "      <th>begin_location</th>\n",
       "      <th>end_range</th>\n",
       "      <th>end_azimuth</th>\n",
       "      <th>end_location</th>\n",
       "      <th>begin_lat</th>\n",
       "      <th>begin_lon</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>episode_narrative</th>\n",
       "      <th>event_narrative</th>\n",
       "      <th>data_source</th>\n",
       "      <th>imputed_damage_property</th>\n",
       "      <th>imputed_damage_crops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>349</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>350</td>\n",
       "      <td>165322</td>\n",
       "      <td>999750</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>C</td>\n",
       "      <td>165</td>\n",
       "      <td>SUMNER</td>\n",
       "      <td>OHX</td>\n",
       "      <td>2021-12-11 03:49:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>2021-12-11 03:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EF0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>50.0</td>\n",
       "      <td>OHX</td>\n",
       "      <td>TN</td>\n",
       "      <td>189</td>\n",
       "      <td>WILSON</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>HUNTERS PT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>HUNTERS PT</td>\n",
       "      <td>36.3178</td>\n",
       "      <td>-86.3235</td>\n",
       "      <td>36.3296</td>\n",
       "      <td>-86.2965</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>This small EF-0 tornado was determined through...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>249</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>254</td>\n",
       "      <td>165322</td>\n",
       "      <td>999613</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>C</td>\n",
       "      <td>43</td>\n",
       "      <td>DICKSON</td>\n",
       "      <td>OHX</td>\n",
       "      <td>2021-12-11 02:49:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>2021-12-11 02:54:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EF0</td>\n",
       "      <td>5.41</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>TIDWELL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>BAKERSWORKS</td>\n",
       "      <td>36.0255</td>\n",
       "      <td>-87.3054</td>\n",
       "      <td>36.0736</td>\n",
       "      <td>-87.2330</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>This tornado developed just southeast of the D...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>325</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>327</td>\n",
       "      <td>165322</td>\n",
       "      <td>999636</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>37</td>\n",
       "      <td>DAVIDSON</td>\n",
       "      <td>OHX</td>\n",
       "      <td>2021-12-11 03:25:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>2021-12-11 03:27:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>74.0</td>\n",
       "      <td>EG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>MAPLEWOOD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>AMQUI</td>\n",
       "      <td>36.2372</td>\n",
       "      <td>-86.7286</td>\n",
       "      <td>36.2572</td>\n",
       "      <td>-86.7035</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>Severe straight-line winds caused significant ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>232</td>\n",
       "      <td>202112</td>\n",
       "      <td>11</td>\n",
       "      <td>239</td>\n",
       "      <td>165322</td>\n",
       "      <td>999604</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>C</td>\n",
       "      <td>81</td>\n",
       "      <td>HICKMAN</td>\n",
       "      <td>OHX</td>\n",
       "      <td>2021-12-11 02:32:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>2021-12-11 02:39:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>NWS Storm Survey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EF1</td>\n",
       "      <td>8.54</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>SPOT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>PINEWOOD</td>\n",
       "      <td>35.9205</td>\n",
       "      <td>-87.6423</td>\n",
       "      <td>35.9725</td>\n",
       "      <td>-87.5068</td>\n",
       "      <td>One of the worst tornado outbreaks ever record...</td>\n",
       "      <td>This tornado touched down in far northwest Hic...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202112</td>\n",
       "      <td>6</td>\n",
       "      <td>724</td>\n",
       "      <td>202112</td>\n",
       "      <td>6</td>\n",
       "      <td>724</td>\n",
       "      <td>165321</td>\n",
       "      <td>999306</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>December</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>C</td>\n",
       "      <td>49</td>\n",
       "      <td>FENTRESS</td>\n",
       "      <td>OHX</td>\n",
       "      <td>2021-12-06 07:24:00</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>2021-12-06 07:24:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00K</td>\n",
       "      <td>0.00K</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>52.0</td>\n",
       "      <td>EG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>JAMESTOWN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>JAMESTOWN</td>\n",
       "      <td>36.4322</td>\n",
       "      <td>-84.9405</td>\n",
       "      <td>36.4322</td>\n",
       "      <td>-84.9405</td>\n",
       "      <td>After some isolated thunderstorms moved across...</td>\n",
       "      <td>A Facebook report indicated trees and power li...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:13.608441Z",
     "start_time": "2024-09-25T03:59:13.276945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the data information\n",
    "df_details.info()"
   ],
   "id": "c4b76d6a6ad4453b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 669746 entries, 0 to 669745\n",
      "Data columns (total 52 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   begin_yearmonth          669746 non-null  int64         \n",
      " 1   begin_day                669746 non-null  int64         \n",
      " 2   begin_time               669746 non-null  int64         \n",
      " 3   end_yearmonth            669746 non-null  int64         \n",
      " 4   end_day                  669746 non-null  int64         \n",
      " 5   end_time                 669746 non-null  int64         \n",
      " 6   episode_id               669746 non-null  object        \n",
      " 7   event_id                 669746 non-null  object        \n",
      " 8   state                    669746 non-null  object        \n",
      " 9   state_fips               669746 non-null  category      \n",
      " 10  year                     669746 non-null  int64         \n",
      " 11  month_name               669746 non-null  category      \n",
      " 12  event_type               669746 non-null  category      \n",
      " 13  cz_type                  669746 non-null  category      \n",
      " 14  cz_fips                  669746 non-null  int64         \n",
      " 15  cz_name                  669746 non-null  object        \n",
      " 16  wfo                      669746 non-null  object        \n",
      " 17  begin_date_time          669746 non-null  datetime64[ns]\n",
      " 18  cz_timezone              669746 non-null  object        \n",
      " 19  end_date_time            669746 non-null  datetime64[ns]\n",
      " 20  injuries_direct          669746 non-null  int64         \n",
      " 21  injuries_indirect        669746 non-null  int64         \n",
      " 22  deaths_direct            669746 non-null  int64         \n",
      " 23  deaths_indirect          669746 non-null  int64         \n",
      " 24  damage_property          533328 non-null  object        \n",
      " 25  damage_crops             535619 non-null  object        \n",
      " 26  source                   669746 non-null  object        \n",
      " 27  magnitude                348945 non-null  float64       \n",
      " 28  magnitude_type           252901 non-null  category      \n",
      " 29  flood_cause              72392 non-null   object        \n",
      " 30  tor_f_scale              15192 non-null   category      \n",
      " 31  tor_length               15192 non-null   float64       \n",
      " 32  tor_width                15192 non-null   float64       \n",
      " 33  tor_other_wfo            1988 non-null    object        \n",
      " 34  tor_other_cz_state       1988 non-null    category      \n",
      " 35  tor_other_cz_fips        1988 non-null    Int64         \n",
      " 36  tor_other_cz_name        1988 non-null    object        \n",
      " 37  begin_range              410429 non-null  float64       \n",
      " 38  begin_azimuth            410429 non-null  object        \n",
      " 39  begin_location           410429 non-null  object        \n",
      " 40  end_range                410429 non-null  float64       \n",
      " 41  end_azimuth              410429 non-null  object        \n",
      " 42  end_location             410429 non-null  object        \n",
      " 43  begin_lat                410429 non-null  float64       \n",
      " 44  begin_lon                410429 non-null  float64       \n",
      " 45  end_lat                  410429 non-null  float64       \n",
      " 46  end_lon                  410429 non-null  float64       \n",
      " 47  episode_narrative        669746 non-null  object        \n",
      " 48  event_narrative          529683 non-null  object        \n",
      " 49  data_source              669746 non-null  object        \n",
      " 50  imputed_damage_property  669746 non-null  float64       \n",
      " 51  imputed_damage_crops     669746 non-null  float64       \n",
      "dtypes: Int64(1), category(7), datetime64[ns](2), float64(11), int64(12), object(19)\n",
      "memory usage: 235.1+ MB\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:59:13.972202Z",
     "start_time": "2024-09-25T03:59:13.636957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Describe the cleaned data\n",
    "df_details.describe()"
   ],
   "id": "442be13af8b6aca9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       begin_yearmonth      begin_day     begin_time  end_yearmonth  \\\n",
       "count    669746.000000  669746.000000  669746.000000  669746.000000   \n",
       "mean     201909.724999      14.884967    1262.750553  201909.724999   \n",
       "min      201401.000000       1.000000       0.000000  201401.000000   \n",
       "25%      201611.000000       7.000000     745.000000  201611.000000   \n",
       "50%      201907.000000      15.000000    1434.000000  201907.000000   \n",
       "75%      202204.000000      23.000000    1800.000000  202204.000000   \n",
       "max      202406.000000      31.000000    2359.000000  202406.000000   \n",
       "std         308.331723       9.061630     677.789666     308.331723   \n",
       "\n",
       "             end_day       end_time           year        cz_fips  \\\n",
       "count  669746.000000  669746.000000  669746.000000  669746.000000   \n",
       "mean       16.502822    1454.988749    2019.038506     108.306182   \n",
       "min         1.000000       0.000000    2014.000000       1.000000   \n",
       "25%         9.000000    1051.000000    2016.000000      25.000000   \n",
       "50%        16.000000    1600.000000    2019.000000      66.000000   \n",
       "75%        24.000000    1900.000000    2022.000000     123.000000   \n",
       "max        31.000000    2359.000000    2024.000000     876.000000   \n",
       "std         9.079046     615.305445       3.084325     136.393570   \n",
       "\n",
       "                     begin_date_time                  end_date_time  \\\n",
       "count                         669746                         669746   \n",
       "mean   2019-06-26 03:09:20.556270848  2019-06-27 19:55:32.801539840   \n",
       "min              2014-01-01 00:00:00            2014-01-01 03:00:00   \n",
       "25%              2016-11-07 17:18:45            2016-11-19 06:00:00   \n",
       "50%              2019-07-10 13:00:00            2019-07-10 20:45:00   \n",
       "75%              2022-04-12 18:15:00            2022-04-13 18:54:45   \n",
       "max              2024-06-30 22:44:00            2024-06-30 23:59:00   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "       injuries_direct  injuries_indirect  deaths_direct  deaths_indirect  \\\n",
       "count    669746.000000      669746.000000  669746.000000    669746.000000   \n",
       "mean          0.027030           0.007848       0.009999         0.003491   \n",
       "min           0.000000           0.000000       0.000000         0.000000   \n",
       "25%           0.000000           0.000000       0.000000         0.000000   \n",
       "50%           0.000000           0.000000       0.000000         0.000000   \n",
       "75%           0.000000           0.000000       0.000000         0.000000   \n",
       "max         806.000000         500.000000     100.000000        25.000000   \n",
       "std           1.724955           0.715775       0.307508         0.104672   \n",
       "\n",
       "           magnitude   tor_length     tor_width  tor_other_cz_fips  \\\n",
       "count  348945.000000  15192.00000  15192.000000             1988.0   \n",
       "mean       37.897867      3.16236    196.235153         105.344064   \n",
       "min         0.130000      0.01000      1.000000                1.0   \n",
       "25%         1.750000      0.50000     50.000000               45.0   \n",
       "50%        50.000000      1.66000    100.000000               91.0   \n",
       "75%        52.000000      4.20000    200.000000              143.0   \n",
       "max       173.000000     41.88000   3960.000000              820.0   \n",
       "std        23.715012      4.14433    296.644097          86.964479   \n",
       "\n",
       "         begin_range      end_range      begin_lat      begin_lon  \\\n",
       "count  410429.000000  410429.000000  410429.000000  410429.000000   \n",
       "mean        2.440858       2.463415      37.648997     -90.233009   \n",
       "min         0.000000       0.000000     -14.400000    -171.032700   \n",
       "25%         1.000000       1.000000      34.310000     -97.260000   \n",
       "50%         1.000000       1.000000      38.140000     -89.530000   \n",
       "75%         3.000000       3.000000      41.220000     -81.460000   \n",
       "max       185.000000     185.000000      70.375400     151.848400   \n",
       "std         4.563890       4.577299       5.177361      11.722470   \n",
       "\n",
       "             end_lat        end_lon  imputed_damage_property  \\\n",
       "count  410429.000000  410429.000000             6.697460e+05   \n",
       "mean       37.647509     -90.226771             3.546832e+05   \n",
       "min       -14.437500    -170.905900             0.000000e+00   \n",
       "25%        34.310000     -97.260000             0.000000e+00   \n",
       "50%        38.140000     -89.517600             0.000000e+00   \n",
       "75%        41.218300     -81.450000             0.000000e+00   \n",
       "max        70.264600     151.858900             1.700000e+10   \n",
       "std         5.178816      11.720015             3.648998e+07   \n",
       "\n",
       "       imputed_damage_crops  \n",
       "count          6.697460e+05  \n",
       "mean           2.254274e+04  \n",
       "min            0.000000e+00  \n",
       "25%            0.000000e+00  \n",
       "50%            0.000000e+00  \n",
       "75%            0.000000e+00  \n",
       "max            1.500000e+09  \n",
       "std            2.461845e+06  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin_yearmonth</th>\n",
       "      <th>begin_day</th>\n",
       "      <th>begin_time</th>\n",
       "      <th>end_yearmonth</th>\n",
       "      <th>end_day</th>\n",
       "      <th>end_time</th>\n",
       "      <th>year</th>\n",
       "      <th>cz_fips</th>\n",
       "      <th>begin_date_time</th>\n",
       "      <th>end_date_time</th>\n",
       "      <th>injuries_direct</th>\n",
       "      <th>injuries_indirect</th>\n",
       "      <th>deaths_direct</th>\n",
       "      <th>deaths_indirect</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>tor_length</th>\n",
       "      <th>tor_width</th>\n",
       "      <th>tor_other_cz_fips</th>\n",
       "      <th>begin_range</th>\n",
       "      <th>end_range</th>\n",
       "      <th>begin_lat</th>\n",
       "      <th>begin_lon</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>imputed_damage_property</th>\n",
       "      <th>imputed_damage_crops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746</td>\n",
       "      <td>669746</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>669746.000000</td>\n",
       "      <td>348945.000000</td>\n",
       "      <td>15192.00000</td>\n",
       "      <td>15192.000000</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>410429.000000</td>\n",
       "      <td>410429.000000</td>\n",
       "      <td>410429.000000</td>\n",
       "      <td>410429.000000</td>\n",
       "      <td>410429.000000</td>\n",
       "      <td>410429.000000</td>\n",
       "      <td>6.697460e+05</td>\n",
       "      <td>6.697460e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>201909.724999</td>\n",
       "      <td>14.884967</td>\n",
       "      <td>1262.750553</td>\n",
       "      <td>201909.724999</td>\n",
       "      <td>16.502822</td>\n",
       "      <td>1454.988749</td>\n",
       "      <td>2019.038506</td>\n",
       "      <td>108.306182</td>\n",
       "      <td>2019-06-26 03:09:20.556270848</td>\n",
       "      <td>2019-06-27 19:55:32.801539840</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>37.897867</td>\n",
       "      <td>3.16236</td>\n",
       "      <td>196.235153</td>\n",
       "      <td>105.344064</td>\n",
       "      <td>2.440858</td>\n",
       "      <td>2.463415</td>\n",
       "      <td>37.648997</td>\n",
       "      <td>-90.233009</td>\n",
       "      <td>37.647509</td>\n",
       "      <td>-90.226771</td>\n",
       "      <td>3.546832e+05</td>\n",
       "      <td>2.254274e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>201401.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>201401.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.400000</td>\n",
       "      <td>-171.032700</td>\n",
       "      <td>-14.437500</td>\n",
       "      <td>-170.905900</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>201611.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>201611.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2016-11-07 17:18:45</td>\n",
       "      <td>2016-11-19 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.310000</td>\n",
       "      <td>-97.260000</td>\n",
       "      <td>34.310000</td>\n",
       "      <td>-97.260000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>201907.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1434.000000</td>\n",
       "      <td>201907.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2019-07-10 13:00:00</td>\n",
       "      <td>2019-07-10 20:45:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.66000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>-89.530000</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>-89.517600</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>202204.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>202204.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>2022-04-12 18:15:00</td>\n",
       "      <td>2022-04-13 18:54:45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>4.20000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>143.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.220000</td>\n",
       "      <td>-81.460000</td>\n",
       "      <td>41.218300</td>\n",
       "      <td>-81.450000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>202406.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>202406.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>2024-06-30 22:44:00</td>\n",
       "      <td>2024-06-30 23:59:00</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>41.88000</td>\n",
       "      <td>3960.000000</td>\n",
       "      <td>820.0</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>70.375400</td>\n",
       "      <td>151.848400</td>\n",
       "      <td>70.264600</td>\n",
       "      <td>151.858900</td>\n",
       "      <td>1.700000e+10</td>\n",
       "      <td>1.500000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>308.331723</td>\n",
       "      <td>9.061630</td>\n",
       "      <td>677.789666</td>\n",
       "      <td>308.331723</td>\n",
       "      <td>9.079046</td>\n",
       "      <td>615.305445</td>\n",
       "      <td>3.084325</td>\n",
       "      <td>136.393570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724955</td>\n",
       "      <td>0.715775</td>\n",
       "      <td>0.307508</td>\n",
       "      <td>0.104672</td>\n",
       "      <td>23.715012</td>\n",
       "      <td>4.14433</td>\n",
       "      <td>296.644097</td>\n",
       "      <td>86.964479</td>\n",
       "      <td>4.563890</td>\n",
       "      <td>4.577299</td>\n",
       "      <td>5.177361</td>\n",
       "      <td>11.722470</td>\n",
       "      <td>5.178816</td>\n",
       "      <td>11.720015</td>\n",
       "      <td>3.648998e+07</td>\n",
       "      <td>2.461845e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a271c1b152fb288c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
